# The LLM Scientist Roadmap

1. The LLM architecture
   1.1 Architectural Overview
   1.2 Tokenization
   1.3 Attention mechanisms
   1.4 Sampling techniques
2. Pre-training models
   2.1 Data preparation
   2.2 Distributed training
   2.3 Training optimization
   2.4 Monitoring
3. Post-training datasets
   3.1 Storage & chat templates
   3.2 Synthetic data generation
   3.3 Data enhancement
   3.4 Quality filtering
4. Supervised Fine-Tuning
   4.1 Training techniques
   4.2 Training parameters
   4.3 Distributed training
   4.4 Monitoring
5. Preference alignment
   5.1 Rejection sampling
   5.2 Direct Preference Optimization
   5.3 Reward model
   5.4 Reinforcement Learning
6. Evaluation
   6.1 Automated benchmarks
   6.2 Human evaluation
   6.3 Model-based evaluation
   6.4 Feedback signal
7. Quantization
   7.1 Base techniques
   7.2 GGUF and llama.cpp
   7.3 GPTQ & AWQ
   7.4 SmoothQuant & ZeroQuant
8. New Trends
   8.1 Model merging
   8.2 Multimodal models
   8.3 Interpretability
   8.4 Test-time compute


# The LLM Engineer Roadmap

1. Running LLMs
   1.1 LLM APIs
   1.2 Open-source LLMs
   1.3 Prompt engineering
   1.4 Structuring outputs
2. Building a Vector Storage
   2.1 Ingesting documents
   2.2 Splitting documents
   2.3 Embedding models
   2.4 Vector databases
3. Retrieval Augmented Generation
   3.1 Orchestrators
   3.2 Retrievers
   3.3 Memory
   3.4 Evaluation
4. Advanced RAG
   4.1 Query construction
   4.2 Agents and tools
   4.3 Post-processing
   4.4 Program LLMs
5. Agents
   5.1 Agent fundamentals
   5.2 Agent frameworks
   5.3 Multi-agents
6. Inference optimization
   6.1 Flash Attention
   6.2 Key-value cache
   6.3 Speculative decoding
7. Deploying LLMs
   7.1 Local deployment
   7.2 Demo deployment
   7.3 Server deployment
   7.4 Edge deployment
8. Securing LLMs
   8.1 Prompt hacking
   8.2 Backdoors
   8.3 Defensive measures
